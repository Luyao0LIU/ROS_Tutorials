## 目标

参考：https://blog.csdn.net/qq_34218078/article/details/109611105

<div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-044f2cf1dc.css">
                <div id="content_views" class="htmledit_views">
                    <div id="cnblogs_post_body" class="blogpost-body" style="font-size: 16px;"> 
 <p>　　神经网络中最重要的就是参数了，其中包括权重项$W$和偏置项$b$。 我们训练神经网络的最终目的就是得到最好的参数，使得目标函数取得最小值。参数的初始化也同样重要，因此微调受到很多人的重视，</p> 
 <p>　　只列一些常用的！</p> 
 <h2><a name="t0"></a>Tensorflow</h2> 
 <h4><a name="t1"></a>常数初始化</h4> 
 <div class="cnblogs_code"> 
  <pre data-index="0" class="set-code-show" name="code"><code class="has hljs language-scss">tf<span class="hljs-selector-class">.constant_initializer</span>(value)</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <p>value取0，则代表的是全0初始化，也可以表示为&nbsp;<span class="cnblogs_code">tf.zeros_initializer()</span>&nbsp;</p> 
 <p>value取1，则代表的是全1初始化，也可以表示为&nbsp;<span class="cnblogs_code">tf.ones_initializer()</span>&nbsp;</p> 
 <h4><a name="t2"></a><strong>随机均匀初始化器</strong></h4> 
 <div class="cnblogs_code"> 
  <pre data-index="1" class="set-code-show" name="code"><code class="has hljs language-cobol">tf.<span class="hljs-keyword">random</span>_uniform_initializer(minval<span class="hljs-operator">=</span><span class="hljs-number">0</span>, maxval<span class="hljs-operator">=</span>None) </code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <p>不需要指定最小值和最大值的均匀初始化：&nbsp;</p> 
 <div class="cnblogs_code"> 
  <pre data-index="2" class="set-code-show" name="code"><code class="has hljs language-cobol">tf.uniform_<span class="hljs-keyword">unit</span>_scaling_initializer(factor<span class="hljs-operator">=</span><span class="hljs-number">1.0</span>) </code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t3"></a>随机正态初始化器</h4> 
 <p>(均值为0，方差为1)</p> 
 <div class="cnblogs_code"> 
  <pre data-index="3" class="set-code-show" name="code"><code class="has hljs language-cobol">tf.<span class="hljs-keyword">random</span>_normal_initializer(mean<span class="hljs-operator">=</span><span class="hljs-number">0.0</span>, stddev<span class="hljs-operator">=</span><span class="hljs-number">1.0</span>) </code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t4"></a>截断正态分布初始化器</h4> 
 <p>(均值为0，方差为1)</p> 
 <div class="cnblogs_code"> 
  <pre data-index="4" class="set-code-show" name="code"><code class="has hljs language-cobol">tf.truncated_normal_initializer(mean<span class="hljs-operator">=</span><span class="hljs-number">0.0</span>, stddev<span class="hljs-operator">=</span><span class="hljs-number">1.0</span>) </code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t5"></a><strong>正交矩阵初始化器</strong></h4> 
 <div class="cnblogs_code"> 
  <pre data-index="5" class="set-code-show" name="code"><code class="has hljs language-scss">tf<span class="hljs-selector-class">.orthogonal_initializer</span>() </code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <p>　　生成正交矩阵的随机数。当需要生成的参数是2维时，这个正交矩阵是由均匀分布的随机数矩阵经过SVD分解而来。</p> 
 <p><strong>Xavier uniform 初始化器</strong></p> 
 <div class="cnblogs_code"> 
  <pre data-index="6" class="set-code-show" name="code"><code class="has hljs language-scss">tf<span class="hljs-selector-class">.glorot_uniform_initializer</span>() </code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <p>　　初始化为与输入输出节点数相关的均匀分布随机数，和xavier_initializer()是一个东西</p> 
 <p>　　假设均匀分布的区间是[-limit, limit]，则</p> 
 <p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>l</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>t</mi><mo>=</mo><msqrt><mfrac><mn>6</mn><mrow><mi>f</mi><mi>a</mi><msub><mi>n</mi><mi>i</mi></msub><mi>n</mi><mo>+</mo><mi>f</mi><mi>a</mi><msub><mi>n</mi><mi>o</mi></msub><mi>u</mi><mi>t</mi></mrow></mfrac></msqrt></math>" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 14.347em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.734em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(0.361em, 1011.73em, 3.64em, -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3" style="font-family: MathJax_Math-italic;">l</span><span class="mi" id="MathJax-Span-4" style="font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-5" style="font-family: MathJax_Math-italic;">m</span><span class="mi" id="MathJax-Span-6" style="font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-7" style="font-family: MathJax_Math-italic;">t</span><span class="mo" id="MathJax-Span-8" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="msqrt" id="MathJax-Span-9" style="padding-left: 0.259em;"><span style="display: inline-block; position: relative; width: 8.199em; height: 0px;"><span style="position: absolute; clip: rect(2.513em, 1007.17em, 5.023em, -999.997em); top: -3.993em; left: 1.027em;"><span class="mrow" id="MathJax-Span-10"><span class="mfrac" id="MathJax-Span-11"><span style="display: inline-block; position: relative; width: 6.919em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(3.179em, 1000.46em, 4.152em, -999.997em); top: -4.659em; left: 50%; margin-left: -0.254em;"><span class="mn" id="MathJax-Span-12" style="font-family: MathJax_Main;">6</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.128em, 1006.82em, 4.357em, -999.997em); top: -3.327em; left: 50%; margin-left: -3.43em;"><span class="mrow" id="MathJax-Span-13"><span class="mi" id="MathJax-Span-14" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="mi" id="MathJax-Span-15" style="font-family: MathJax_Math-italic;">a</span><span class="msubsup" id="MathJax-Span-16"><span style="display: inline-block; position: relative; width: 0.925em; height: 0px;"><span style="position: absolute; clip: rect(3.384em, 1000.57em, 4.152em, -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-17" style="font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.617em;"><span class="mi" id="MathJax-Span-18" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mi" id="MathJax-Span-19" style="font-family: MathJax_Math-italic;">n</span><span class="mo" id="MathJax-Span-20" style="font-family: MathJax_Main; padding-left: 0.207em;">+</span><span class="mi" id="MathJax-Span-21" style="font-family: MathJax_Math-italic; padding-left: 0.207em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="mi" id="MathJax-Span-22" style="font-family: MathJax_Math-italic;">a</span><span class="msubsup" id="MathJax-Span-23"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.384em, 1000.57em, 4.152em, -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-24" style="font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.617em;"><span class="mi" id="MathJax-Span-25" style="font-size: 70.7%; font-family: MathJax_Math-italic;">o</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mi" id="MathJax-Span-26" style="font-family: MathJax_Math-italic;">u</span><span class="mi" id="MathJax-Span-27" style="font-family: MathJax_Math-italic;">t</span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em, 1006.92em, 1.232em, -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 6.919em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.589em, 1007.23em, 3.947em, -999.997em); top: -5.377em; left: 1.027em;"><span style="display: inline-block; position: relative; width: 7.226em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -3.993em; left: -0.1em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -3.993em; left: 6.509em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 0.464em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 0.976em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 1.539em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 2.103em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 2.666em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 3.179em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 3.742em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 4.306em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 4.869em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 5.433em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 5.945em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(2.103em, 1001.03em, 5.382em, -999.997em); top: -3.942em; left: 0em;"><span style="font-family: MathJax_Size4;">√</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.622em; border-left: 0px solid; width: 0px; height: 3.816em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>l</mi><mi>i</mi><mi>m</mi><mi>i</mi><mi>t</mi><mo>=</mo><msqrt><mfrac><mn>6</mn><mrow><mi>f</mi><mi>a</mi><msub><mi>n</mi><mi>i</mi></msub><mi>n</mi><mo>+</mo><mi>f</mi><mi>a</mi><msub><mi>n</mi><mi>o</mi></msub><mi>u</mi><mi>t</mi></mrow></mfrac></msqrt></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-1">limit=\sqrt{\frac{6}{fan_in + fan_out}}</script></p> 
 <p>其中的fan_in和fan_out分别表示输入单元的结点数和输出单元的结点数。</p> 
 <p><strong>Xavier normal 初始化器</strong></p> 
 <div class="cnblogs_code"> 
  <pre data-index="7" class="set-code-show" name="code"><code class="has hljs language-scss">tf<span class="hljs-selector-class">.glorot_normal_initializer</span>() </code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <p>　　初始化为与输入输出节点数相关的截断正太分布随机数</p> 
 <p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>s</mi><mi>t</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>v</mi><mo>=</mo><msqrt><mfrac><mn>2</mn><mrow><mi>f</mi><mi>a</mi><mi>n</mi><mi mathvariant=&quot;normal&quot;>&amp;#x005F;</mi><mi>i</mi><mi>n</mi><mo>+</mo><mi>f</mi><mi>a</mi><mi>n</mi><mi mathvariant=&quot;normal&quot;>&amp;#x005F;</mi><mi>o</mi><mi>u</mi><mi>t</mi></mrow></mfrac></msqrt></math>" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-28" style="width: 16.396em; display: inline-block;"><span style="display: inline-block; position: relative; width: 13.425em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(0.361em, 1013.42em, 3.64em, -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-29"><span class="mi" id="MathJax-Span-30" style="font-family: MathJax_Math-italic;">s</span><span class="mi" id="MathJax-Span-31" style="font-family: MathJax_Math-italic;">t</span><span class="mi" id="MathJax-Span-32" style="font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-33" style="font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-34" style="font-family: MathJax_Math-italic;">e</span><span class="mi" id="MathJax-Span-35" style="font-family: MathJax_Math-italic;">v</span><span class="mo" id="MathJax-Span-36" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="msqrt" id="MathJax-Span-37" style="padding-left: 0.259em;"><span style="display: inline-block; position: relative; width: 9.275em; height: 0px;"><span style="position: absolute; clip: rect(2.513em, 1008.25em, 5.023em, -999.997em); top: -3.993em; left: 1.027em;"><span class="mrow" id="MathJax-Span-38"><span class="mfrac" id="MathJax-Span-39"><span style="display: inline-block; position: relative; width: 8.046em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(3.179em, 1000.46em, 4.152em, -999.997em); top: -4.659em; left: 50%; margin-left: -0.254em;"><span class="mn" id="MathJax-Span-40" style="font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.128em, 1007.89em, 4.357em, -999.997em); top: -3.327em; left: 50%; margin-left: -3.942em;"><span class="mrow" id="MathJax-Span-41"><span class="mi" id="MathJax-Span-42" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="mi" id="MathJax-Span-43" style="font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-44" style="font-family: MathJax_Math-italic;">n</span><span class="mi" id="MathJax-Span-45" style="font-family: MathJax_Main;">_</span><span class="mi" id="MathJax-Span-46" style="font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-47" style="font-family: MathJax_Math-italic;">n</span><span class="mo" id="MathJax-Span-48" style="font-family: MathJax_Main; padding-left: 0.207em;">+</span><span class="mi" id="MathJax-Span-49" style="font-family: MathJax_Math-italic; padding-left: 0.207em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="mi" id="MathJax-Span-50" style="font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-51" style="font-family: MathJax_Math-italic;">n</span><span class="mi" id="MathJax-Span-52" style="font-family: MathJax_Main;">_</span><span class="mi" id="MathJax-Span-53" style="font-family: MathJax_Math-italic;">o</span><span class="mi" id="MathJax-Span-54" style="font-family: MathJax_Math-italic;">u</span><span class="mi" id="MathJax-Span-55" style="font-family: MathJax_Math-italic;">t</span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em, 1008.05em, 1.232em, -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 8.046em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.589em, 1008.3em, 3.947em, -999.997em); top: -5.377em; left: 1.027em;"><span style="display: inline-block; position: relative; width: 8.302em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -3.993em; left: -0.1em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -3.993em; left: 7.585em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 0.464em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 0.976em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 1.539em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 2.103em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 2.666em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 3.179em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 3.742em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 4.306em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 4.869em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 5.382em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 5.945em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 6.509em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.993em; left: 7.072em;">−<span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(2.103em, 1001.03em, 5.382em, -999.997em); top: -3.942em; left: 0em;"><span style="font-family: MathJax_Size4;">√</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.622em; border-left: 0px solid; width: 0px; height: 3.816em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>s</mi><mi>t</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>v</mi><mo>=</mo><msqrt><mfrac><mn>2</mn><mrow><mi>f</mi><mi>a</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>n</mi><mo>+</mo><mi>f</mi><mi>a</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>o</mi><mi>u</mi><mi>t</mi></mrow></mfrac></msqrt></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-2">stddev = \sqrt{\frac{2}{fan\_in + fan\_out}}</script></p> 
 <p>其中的fan_in和fan_out分别表示输入单元的结点数和输出单元的结点数。</p> 
 <p><strong>变尺度正态、均匀分布</strong></p> 
 <div class="cnblogs_code"> 
  <pre data-index="8" class="set-code-show" name="code"><code class="has hljs language-cobol">tf.variance_scaling_initializer(scale<span class="hljs-operator">=</span><span class="hljs-number">1.0</span>,<span class="hljs-keyword">mode</span><span class="hljs-operator">=</span><span class="hljs-string">"fan_in"</span>, distribution<span class="hljs-operator">=</span><span class="hljs-string">"truncated_normal"</span>)</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <ul><li>scale: 缩放尺度</li><li>mode： 有3个值可选，分别是 “fan_in”, “fan_out” 和 “fan_avg”，用于控制计算标准差 stddev的值</li><li>distribution： 2个值可选，”normal”或“uniform”，定义生成的tensor的分布是截断正太分布还是均匀分布</li></ul> 
 <p>distribution选‘normal’的时候，生成的是截断正太分布，标准差 stddev = sqrt(scale / n), n的取值根据mode的不同设置而不同：</p> 
 <ul><li>mode = "fan_in"， n为输入单元的结点数；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;</li><li>mode = "fan_out"，n为输出单元的结点数；</li><li>mode = "fan_avg",n为输入和输出单元结点数的平均值;</li></ul> 
 <p>distribution选 ‘uniform’，生成均匀分布的随机数tensor，最大值 max_value和 最小值 min_value 的计算公式：</p> 
 <ul><li>max_value = sqrt(3 * scale / n)</li><li>min_value = -max_value</li></ul> 
 <p><strong>he初始化</strong></p> 
 <p>　　如果使用relu激活函数，最好使用He初始化，因为在ReLU网络中，假定每一层有一半的神经元被激活，另一半为0，所有要保持variance不变。</p> 
 <div class="cnblogs_code"> 
  <pre data-index="9" class="set-code-show" name="code"><code class="has hljs language-scss">tf<span class="hljs-selector-class">.contrib</span><span class="hljs-selector-class">.layers</span><span class="hljs-selector-class">.variance_scaling_initializer</span>()</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <p><strong>Xavier初始化</strong></p> 
 <p>如果激活函数用sigmoid和tanh，最好用xavier初始化器，</p> 
 <p>Xavier初始化的基本思想是保持输入和输出的方差一致，这样就避免了所有输出值都趋向于0.</p> 
 <div class="cnblogs_code"> 
  <pre data-index="10" class="set-code-show" name="code"><code class="has hljs language-typescript"><span class="hljs-keyword">from</span> tensorflow.<span class="hljs-property">contrib</span>.<span class="hljs-property">layers</span> <span class="hljs-keyword">import</span> xavier_initializer</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h2><a name="t6"></a>pytorch</h2> 
 <p>PyTorch 中参数的默认初始化在各个层的&nbsp;<code>reset_parameters()</code>&nbsp;方法中。例如：<code>nn.Linear</code>&nbsp;和&nbsp;<code>nn.Conv2D</code>，都是在 [-limit, limit] 之间的均匀分布(Uniform distribution)，其中 limit 是$\frac{1}{\sqrt{fan\_in}}$&nbsp;，fan_in是指参数张量(tensor)的输入单元的数量</p> 
 <p>下面是几种常见的初始化方式</p> 
 <h4><a name="t7"></a>常数初始化</h4> 
 <div class="cnblogs_code"> 
  <pre data-index="11" class="set-code-show" name="code"><code class="has hljs language-cobol">nn.init.<span class="hljs-keyword">constant</span>_(w, <span class="hljs-number">0.3</span>)</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t8"></a><strong>均匀分布</strong></h4> 
 <div class="cnblogs_code"> 
  <pre data-index="12" class="set-code-show" name="code"><code class="has hljs language-csharp">nn.<span class="hljs-keyword">init</span>.uniform_(w)</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t9"></a><strong>正态分布</strong></h4> 
 <div class="cnblogs_code"> 
  <pre data-index="13" class="set-code-show" name="code"><code class="has hljs language-cobol">nn.init.normal_(w, mean<span class="hljs-operator">=</span><span class="hljs-number">0</span>, std<span class="hljs-operator">=</span><span class="hljs-number">1</span>)</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t10"></a>xavier_uniform 初始化</h4> 
 <p>　　Xavier初始化的基本思想是保持输入和输出的方差一致，这样就避免了所有输出值都趋向于0。这是通用的方法，适用于任何激活函数。</p> 
 <div class="cnblogs_code"> 
  <pre data-index="14" class="set-code-show" name="code"><code class="has hljs language-scss"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"># 默认方法</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">for m in model<span class="hljs-selector-class">.modules</span>():</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    if <span class="hljs-built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        nn.init.<span class="hljs-built_in">xavier_uniform_</span>(m.weight)</div></div></li></ol></code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <p>&nbsp;也可以使用&nbsp;<code>gain</code>&nbsp;参数来自定义初始化的标准差来匹配特定的激活函数：</p> 
 <div class="cnblogs_code"> 
  <pre data-index="15" class="set-code-show" name="code"><code class="has hljs language-scss"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">for m in model<span class="hljs-selector-class">.modules</span>():</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    if <span class="hljs-built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        nn.init.<span class="hljs-built_in">xavier_uniform_</span>(m.<span class="hljs-built_in">weight</span>(), gain=nn.init.<span class="hljs-built_in">calculate_gain</span>(<span class="hljs-string">'relu'</span>))</div></div></li></ol></code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t11"></a>xavier_normal 初始化</h4> 
 <div class="cnblogs_code"> 
  <pre data-index="16" class="set-code-show" name="code"><code class="has hljs language-csharp">nn.<span class="hljs-keyword">init</span>.xavier_normal_(w)</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t12"></a>kaiming_uniform 初始化</h4> 
 <div class="cnblogs_code"> 
  <pre data-index="17" class="set-code-show" name="code"><code class="has hljs language-cobol">nn.init.kaiming_uniform_(w, <span class="hljs-keyword">mode</span><span class="hljs-operator">=</span><span class="hljs-string">'fan_in'</span>, nonlinearity<span class="hljs-operator">=</span><span class="hljs-string">'relu'</span>)</code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t13"></a>kaiming_normal 初始化</h4> 
 <p>　　He initialization的思想是：在ReLU网络中，假定每一层有一半的神经元被激活，另一半为0。推荐在ReLU网络中使用。</p> 
 <div class="cnblogs_code"> 
  <pre data-index="18" class="set-code-show" name="code"><code class="has hljs language-scss"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">for m in model<span class="hljs-selector-class">.modules</span>():</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    if <span class="hljs-built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        nn.init.<span class="hljs-built_in">kaiming_normal_</span>(m.weight, mode=<span class="hljs-string">'fan_in'</span>)</div></div></li></ol></code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t14"></a>正交初始化(Orthogonal Initialization)</h4> 
 <p>　　主要用以解决深度网络下的梯度消失、梯度爆炸问题，在RNN中经常使用的参数初始化方法。</p> 
 <div class="cnblogs_code"> 
  <pre data-index="19" class="set-code-show" name="code"><code class="has hljs language-scss"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">for m in model<span class="hljs-selector-class">.modules</span>():</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    if <span class="hljs-built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        nn.init.<span class="hljs-built_in">orthogonal</span>(m.weight)</div></div></li></ol></code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h4><a name="t15"></a>Batchnorm Initialization</h4> 
 <p>　　在非线性激活函数之前，我们想让输出值有比较好的分布(例如高斯分布)，以便于计算梯度和更新参数。Batch Normalization 将输出值强行做一次 Gaussian Normalization 和线性变换：</p> 
 <p></p> 
 <div style="text-align: center;"> 
  <img src="https://img-blog.csdnimg.cn/img_convert/5f010d63654eacb42ec6ff2c45625f90.png" alt="" style="outline: none;"> 
 </div> 
 <div class="cnblogs_code"> 
  <pre data-index="20" class="set-code-show" name="code"><code class="has hljs language-cobol"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> model:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">if</span> isinstance(m, nn.BatchNorm<span class="hljs-number">2</span>d):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        nn.init.<span class="hljs-keyword">constant</span>(m.weight, <span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        nn.init.<span class="hljs-keyword">constant</span>(m.bias, <span class="hljs-number">0</span>)</div></div></li></ol></code>
<div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> 
 </div> 
 <h2><a name="t16"></a>参考</h2> 
 <p id="articleContentId" class="title-article"><a href="https://blog.csdn.net/m0_37167788/article/details/79073070" target="_blank" rel="noopener noreferrer">tensorflow 学习笔记(九)- 参数初始化(initializer)</a></p> 
 <p id="articleContentId" class="title-article"><a href="https://blog.csdn.net/ys1305/article/details/94332007" target="_blank" rel="noopener noreferrer">pytorch中的参数初始化方法总结</a></p> 
</div>
                </div><div><div></div></div>
        </div>

### 原理
